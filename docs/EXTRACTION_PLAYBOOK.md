# Extraction Playbook

Step-by-step instructions for AI-driven data extraction and analysis.

**Persona:** `@data` (see CLAUDE.md)

## Overview

Two-stage process with persistent storage of AI-analyzed commits:

1. **Extract** raw git data (ephemeral)
2. **AI analyzes** each commit message and assigns tags + complexity
3. **Store** in `processed/` folder (persistent, source of truth)
4. **Aggregate** to dashboard (generated from processed)

## Triggers

| Trigger | Action |
|---------|--------|
| **"hatch the chicken"** | Full reset - delete everything, extract all repos, AI analyzes ALL commits, save to `processed/`, aggregate to dashboard |
| **"feed the chicken"** | Incremental - extract repos, AI analyzes only NEW commits (not in `processed/`), update `processed/`, re-aggregate |

## Batch Processing Strategy

Human-in-the-loop review ensures quality tagging.

### Batch Size
- Process **10 commits per batch**
- AI presents analysis, **user reviews and approves**
- After approval: write to `processed/`, update checkpoint
- If session ends, work is saved at last approved batch

### Review Format

For each batch, AI presents commits like this:

```
[1/10] abc123
Subject: Fix button placement and performance issues
Body:
- Move "Update Visualization" button below the image
- Fix page freeze on visualization update by removing scrollIntoView
- Optimize DOM manipulation using classList.toggle
- Update help documentation to reflect UI changes

Tags: refactor, bugfix, performance, docs
Complexity: 4
---
[2/10] def456
...
```

User responds:
- **"approve"** - Save all 10 and continue to next batch
- **"#3 should be feature not refactor"** - AI corrects and re-presents
- **"stop"** - Save progress and end session

### Benefits
- **Accurate**: Human review catches AI mistakes
- **Multi-tag**: AI reads full message, assigns ALL relevant tags
- **Resilient**: Progress saved after each approved batch
- **Incremental**: Can stop and continue anytime

## File Structure

```
reports/                      # Raw extracted data (ephemeral)
  <repo-name>/
    commits.json              # All commits (raw, no AI tags)
    batches/                  # Split into files of 10 for AI review
      batch-001.json          # Commits 1-10
      batch-002.json          # Commits 11-20
      ...
    metadata.json
    data.json

processed/                    # AI-analyzed data (committed to git)
  <repo-name>/
    batches/                  # Approved batches copied here
      batch-001.json          # Approved with AI tags
      batch-002.json
      ...
    metadata.json

config/
  repos.json                  # Tracked repositories
  author-map.json             # Author identity mapping

dashboard/
  data.json                   # Aggregated from processed/
```

**Progress tracking:**
- Compare `reports/<repo>/batches/` vs `processed/<repo>/batches/`
- If `batch-005.json` exists in processed/, it's done
- Next batch = first batch file NOT in processed/

**What's committed to git:**
- `processed/*/batches/*.json` - AI-analyzed commits (source of truth)
- `reports/*/*.json` (except batches/) - Repo metadata
- `dashboard/data.json` - Aggregated dashboard data

**What's gitignored (working files):**
- `reports/*/batches/` - Raw batch files (regenerated by extract)
- `.repo-cache/` - Cloned repositories

---

## Hatch the Chicken (Full Reset)

Use when: Starting fresh, schema changes, or need to reprocess everything.

### Step 1: Clean Slate

```bash
# Delete ALL extracted and processed data
rm -rf processed/
rm -rf reports/

# Delete dashboard aggregated data
rm -f dashboard/commits.json dashboard/data.json dashboard/summary.json dashboard/metadata.json dashboard/contributors.json dashboard/files.json
```

**What gets deleted:**
- `processed/` - All AI-analyzed batches
- `reports/` - All raw extracted data and batch files
- `dashboard/*.json` - Aggregated dashboard data

**What's preserved:**
- `config/repos.json` - List of tracked repos
- `config/author-map.json` - Author identity mapping
- `dashboard/index.html` - Dashboard UI

### Step 2: Extract Each Repository

For each repo in `config/repos.json`:

```bash
# Clone/update repo
scripts/update-all.sh
```

This puts raw repo data in `.repo-cache/`.

### Step 3: AI Analyze Each Repository (Human Review)

For each repository, process batch files one at a time:

**Per batch file:**
1. Find next batch: first `batch-NNN.json` in `reports/<repo>/batches/` NOT in `processed/<repo>/batches/`
2. Read the batch file (10 commits with subject + body)
3. AI analyzes each commit and proposes:
   - Tags (multiple allowed, based on full message content)
   - Complexity score (1-5)
4. Present to user in review format (see above)
5. User approves or requests corrections
6. On approval: copy batch file to `processed/<repo>/batches/batch-NNN.json` (with AI tags added)
7. Commit: `git commit -m "chore: process <repo> batch NNN"`

**User commands:**
- `approve` - Save batch to processed/, continue to next
- `#N tag1, tag2` - Correct tags for commit N, re-present
- `stop` - End session (progress is saved)

**Repeat until all batch files processed or user stops.**

**Progress check:**
```bash
# See what's done vs pending
ls reports/<repo>/batches/   # All batches
ls processed/<repo>/batches/ # Completed batches
```

**Verification per repo:**
- [ ] Every commit has at least one tag
- [ ] Every commit has complexity 1-5
- [ ] Tags reflect FULL message content (subject + body)
- [ ] Same number of batch files in processed/ as reports/

### Step 4: Aggregate to Dashboard

Combine all `processed/` data into dashboard files:

```bash
node scripts/aggregate.js
```

### Step 5: Commit Changes

```bash
git add processed/ dashboard/
git commit -m "chore: hatch the chicken - full extraction"
git push
```

---

## Feed the Chicken (Incremental)

Use when: Adding new commits OR resuming interrupted processing.

### Step 1: Check Current State

For each repository, read `processed/<repo>/checkpoint.json`:
- If `processed_count < total_count`: Resume from checkpoint
- If no checkpoint: Check for new commits since last extraction

### Step 2: Extract Fresh Data

```bash
scripts/update-all.sh
```

### Step 3: Find Unprocessed Commits

For each repository:

1. Load existing `processed/<repo>/commits.json` (if exists)
2. Get set of processed commit SHAs
3. Compare against freshly extracted commits
4. Identify commits NOT in processed (these need analysis)

### Step 4: AI Analyze with Human Review

Process batch files one at a time:

**Per batch file:**
1. Find next unprocessed batch (in reports/ but not in processed/)
2. AI proposes tags + complexity for each commit
3. Present to user for review
4. User approves or corrects
5. Save approved batch to `processed/<repo>/batches/`
6. Commit changes

**Stop when:**
- All batch files processed, OR
- User says "stop" (progress saved at last approved batch)

**Verification:**
- [ ] Only new batches were analyzed
- [ ] Existing batches unchanged
- [ ] Tags reflect full message content
- [ ] Batch counts match between reports/ and processed/

### Step 5: Re-aggregate to Dashboard

```bash
node scripts/aggregate.js
```

### Step 6: Commit Changes

```bash
git add processed/ dashboard/
git commit -m "chore: feed the chicken - X new commits"
git push
```

---

## Tagging Guidelines

AI reads the full commit message (subject + body) and assigns ALL tags that apply.
Multiple tags per commit is expected and encouraged.

### Tags by Category

**User-Facing Work:**
| Tag | What work was done |
|-----|-------------------|
| `feature` | Built something new for users |
| `enhancement` | Improved existing functionality |
| `bugfix` | Fixed broken behavior |
| `hotfix` | Urgent production fix |
| `ui` | Visual/interface changes |
| `ux` | User experience flow improvements |
| `accessibility` | Accessibility (a11y) improvements |
| `i18n` | Internationalization support |
| `localization` | Translations |

**Code Changes:**
| Tag | What work was done |
|-----|-------------------|
| `refactor` | Restructured code |
| `simplify` | Reduced complexity |
| `removal` | Deleted dead code/files |
| `deprecation` | Marked something as deprecated |
| `migration` | Migrated to new approach/library |
| `naming` | Renamed variables/functions/files |
| `types` | Type definitions/annotations |

**Performance:**
| Tag | What work was done |
|-----|-------------------|
| `performance` | Speed improvements |
| `memory` | Memory optimization |
| `caching` | Added/improved caching |

**Security:**
| Tag | What work was done |
|-----|-------------------|
| `security` | General security work |
| `auth` | Authentication changes |
| `authorization` | Permissions/access control |
| `vulnerability` | Fixed security vulnerability |
| `sanitization` | Input validation |

**Testing:**
| Tag | What work was done |
|-----|-------------------|
| `test-unit` | Unit tests |
| `test-integration` | Integration tests |
| `test-e2e` | End-to-end tests |
| `test-fix` | Fixed broken tests |
| `coverage` | Improved test coverage |
| `mocks` | Test mocks/fixtures |

**Documentation:**
| Tag | What work was done |
|-----|-------------------|
| `docs` | Documentation files (README, guides) |
| `changelog` | Changelog/history updates |
| `comments` | Code comments |
| `api-docs` | API documentation |
| `examples` | Code examples/samples |

**Infrastructure:**
| Tag | What work was done |
|-----|-------------------|
| `ci` | CI pipelines |
| `cd` | Deployment automation |
| `docker` | Containerization |
| `monitoring` | Logging/observability |
| `hosting` | Hosting/server config |

**Build & Config:**
| Tag | What work was done |
|-----|-------------------|
| `build` | Build system |
| `bundler` | Bundler config (webpack, vite) |
| `config` | App configuration |
| `env` | Environment variables |
| `lint` | Linter rules |
| `formatter` | Code formatter config |

**Dependencies:**
| Tag | What work was done |
|-----|-------------------|
| `dependency-add` | Added new dependency |
| `dependency-update` | Upgraded dependency |
| `dependency-remove` | Removed dependency |
| `dependency-security` | Security patch for dependency |

**Database:**
| Tag | What work was done |
|-----|-------------------|
| `database` | Database changes |
| `schema` | Schema changes |
| `data-migration` | Data migration |
| `seed` | Seed/fixture data |

**API:**
| Tag | What work was done |
|-----|-------------------|
| `api` | API changes |
| `api-breaking` | Breaking API change |
| `endpoint` | New/modified endpoint |

**Git/Process:**
| Tag | What work was done |
|-----|-------------------|
| `merge` | Merge commit |
| `revert` | Reverted previous change |
| `release` | Version bump/release |
| `init` | Initial project setup |

**Code Style:**
| Tag | What work was done |
|-----|-------------------|
| `style` | Formatting changes |
| `imports` | Organized imports |
| `whitespace` | Whitespace only changes |

**Error Handling:**
| Tag | What work was done |
|-----|-------------------|
| `error-handling` | Improved error handling |
| `logging` | Added/improved logging |
| `validation` | Input validation |

### Complexity Score (1-5)

Based on scope and impact of changes:

| Score | Description |
|-------|-------------|
| 1 | Trivial - single file, minor change |
| 2 | Small - few files, straightforward change |
| 3 | Medium - multiple files, moderate complexity |
| 4 | Large - many files, significant changes |
| 5 | Major - extensive changes, high complexity |

### Examples

| Commit Subject | Body Summary | Tags |
|----------------|--------------|------|
| "Add dark mode toggle" | New toggle in settings, persists to localStorage | `feature`, `ui` |
| "Fix crash on startup" | Null check was missing | `bugfix` |
| "Fix XSS vulnerability in login" | Sanitize user input | `bugfix`, `vulnerability`, `sanitization` |
| "Refactor auth module" | Extract JWT logic, add types | `refactor`, `types` |
| "Update session notes" | Document today's changes | `docs` |
| "Add comments explaining auth flow" | Why comments in auth.js | `comments` |
| "Merge pull request #42" | (administrative) | `merge` |
| "Upgrade React to v19" | Breaking changes addressed | `dependency-update`, `migration` |
| "Add user API endpoint" | New /api/users route | `feature`, `endpoint`, `api` |
| "Optimize image loading" | Lazy load, reduce bundle | `performance`, `ux` |

---

## Data Schema

### Commit Object

```json
{
  "hash": "abc123",
  "author_id": "john-doe",
  "timestamp": "2026-01-19T10:30:00Z",
  "message": "Add user authentication flow",
  "tags": ["feature", "security"],
  "complexity": 3,
  "files_changed": 5,
  "lines_added": 120,
  "lines_deleted": 15
}
```

### Metadata Object

```json
{
  "repo_id": "my-repo",
  "extracted_at": "2026-01-19T12:00:00Z",
  "commit_count": 150,
  "authors": {
    "john-doe": {
      "name": "John Doe",
      "email": "john@example.com"
    }
  }
}
```

---

*Last updated: 2026-01-19 - Comprehensive 55+ tag list for granular commit analysis*
